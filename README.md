
ğŸš€ **Just Launched: VisuMind â€“ AI-Powered Knowledge Explorer**
App will be available at https://visumind.vercel.app/

Iâ€™m super excited to share my latest project: **VisuMind**, a **multimodal research assistant** powered by **OpenAI APIs** ğŸ§ ğŸ’¡  

Upload PDFs, screenshots, or short videos â€” and simply **ask questions in natural language** like:  
> â€œWhat are the main challenges discussed in this report and presentation?â€

VisuMind automatically:
âœ… Extracts content (OCR + transcription)  
âœ… Understands visuals (image analysis with GPT-4o)  
âœ… Summarizes key points  
âœ… Answers your questions with context & citations  
âœ… Lets you search **across all file types**  

---

ğŸ’¡ **Built with**
- **Frontend:** Next.js 14, Tailwind, shadcn/ui, Framer Motion  
- **Backend:** Node.js (Next.js API Routes)  
- **AI:** OpenAI GPT-4o, Whisper, Embeddings  
- **Database:** Mongodb
- **Deployment:** Vercel 

---

ğŸŒ **Try it live:** [https://visumind.vercel.app/](https://visumind.vercel.app/)  
---

ğŸ¯ **Why this matters:**  
We live in a world of scattered information â€” PDFs, screenshots, lectures.  
VisuMind brings it all together, making **AI-driven multimodal understanding** accessible to everyone.
